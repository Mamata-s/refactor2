  0%|                                                                                                                                                                   | 0/7 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/cidar/Desktop/refactor2/train_patch_gan.py", line 140, in <module>
    train(opt,model,train_dataloader,eval_dataloader,wandb = wandb)
  File "/home/cidar/Desktop/refactor2/train_patch_gan.py", line 34, in train
    images = train_epoch_patch_gan(opt,model,train_dataloader,epoch,epoch_losses)
  File "/home/cidar/Desktop/refactor2/utils/train_epoch.py", line 138, in train_epoch_patch_gan
    model.optimize()
  File "/home/cidar/Desktop/refactor2/models/patch_gan.py", line 117, in optimize
    self.forward()
  File "/home/cidar/Desktop/refactor2/models/patch_gan.py", line 95, in forward
    self.fake_images = self.net_G(self.images)
  File "/home/cidar/anaconda3/envs/resolution_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cidar/Desktop/refactor2/models/unet.py", line 381, in forward
    x = module(before_pool, x)
  File "/home/cidar/anaconda3/envs/resolution_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cidar/Desktop/refactor2/models/unet.py", line 270, in forward
    y = self.conv1(merged_layer)  # convolution 1
  File "/home/cidar/anaconda3/envs/resolution_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cidar/anaconda3/envs/resolution_env/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 423, in forward
    return self._conv_forward(input, self.weight)
  File "/home/cidar/anaconda3/envs/resolution_env/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 419, in _conv_forward
    return F.conv2d(input, weight, self.bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 180.00 MiB (GPU 0; 23.69 GiB total capacity; 6.24 GiB already allocated; 211.62 MiB free; 6.30 GiB reserved in total by PyTorch)